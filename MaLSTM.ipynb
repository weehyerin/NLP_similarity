{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 미리 Global 변수를 지정하자. 파일 명, 파일 위치, 디렉토리 등이 있다.\n",
    "\n",
    "DATA_IN_PATH = './data_in/'\n",
    "DATA_OUT_PATH = './data_out/'\n",
    "\n",
    "TRAIN_Q1_DATA_FILE = 'train_q1.npy'\n",
    "TRAIN_Q2_DATA_FILE = 'train_q2.npy'\n",
    "TRAIN_LABEL_DATA_FILE = 'train_label.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "\n",
    "## 학습에 필요한 파라메터들에 대해서 지정하는 부분이다.\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCH = 2\n",
    "HIDDEN = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "NUM_LAYERS = 4\n",
    "DROPOUT_RATIO = 0.3\n",
    "\n",
    "TEST_SPLIT = 0.1\n",
    "RNG_SEED = 13371447\n",
    "EMBEDDING_DIM = 128\n",
    "MAX_SEQ_LEN = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터를 불러오는 부분이다. 효과적인 데이터 불러오기를 위해, 미리 넘파이 형태로 저장시킨 데이터를 로드한다.\n",
    "\n",
    "q1_data = np.load(open(DATA_IN_PATH + TRAIN_Q1_DATA_FILE, 'rb'))\n",
    "q2_data = np.load(open(DATA_IN_PATH + TRAIN_Q2_DATA_FILE, 'rb'))\n",
    "labels = np.load(open(DATA_IN_PATH + TRAIN_LABEL_DATA_FILE, 'rb'))\n",
    "prepro_configs = None\n",
    "\n",
    "with open(DATA_IN_PATH + DATA_CONFIGS, 'r') as f:\n",
    "    prepro_configs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = prepro_configs['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_data_len = np.array([min(len(x), MAX_SEQ_LEN) for x in q1_data])\n",
    "q2_data_len = np.array([min(len(x), MAX_SEQ_LEN) for x in q2_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터를 나누어 저장하자. sklearn의 train_test_split을 사용하면 유용하다. 하지만, 쿼라 데이터의 경우는\n",
    "## 입력이 1개가 아니라 2개이다. 따라서, np.stack을 사용하여 두개를 하나로 쌓은다음 활용하여 분류한다.\n",
    "\n",
    "X = np.stack((q1_data, q2_data), axis=1)\n",
    "y = labels\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RNG_SEED)\n",
    "\n",
    "train_Q1 = train_X[:,0]\n",
    "train_Q2 = train_X[:,1]\n",
    "test_Q1 = test_X[:,0]\n",
    "test_Q2 = test_X[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange(base, hypothesis, labels):\n",
    "    features = {\"base\": base, \"hypothesis\": hypothesis}\n",
    "    return features, labels\n",
    "\n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((train_Q1, train_Q2, train_y))\n",
    "    dataset = dataset.shuffle(buffer_size=len(train_Q1))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(rearrange)\n",
    "    dataset = dataset.repeat(EPOCH)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()\n",
    "\n",
    "def eval_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((test_Q1, test_Q2, test_y))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(rearrange)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Malstm(features, labels, mode):\n",
    "        \n",
    "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
    "    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
    "    \n",
    "    def basic_bilstm_network(inputs, name):\n",
    "        with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
    "            #NUM_LAYERS 수만큼 쌓기(fw : 전방, bw : 후방)\n",
    "            lstm_fw = [\n",
    "                tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(HIDDEN),output_keep_prob=DROPOUT_RATIO)\n",
    "                for layer in range(NUM_LAYERS)\n",
    "            ]\n",
    "            lstm_bw = [\n",
    "                tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(HIDDEN),output_keep_prob=DROPOUT_RATIO)\n",
    "                for layer in range(NUM_LAYERS)\n",
    "            ]\n",
    "            # 'MultiRNNCELL'을 통해 여러 층이 쌓인 LSTM을 묶는다.\n",
    "            multi_lstm_fw = tf.nn.rnn_cell.MultiRNNCell(lstm_fw)\n",
    "            multi_lstm_bw = tf.nn.rnn_cell.MultiRNNCell(lstm_bw)\n",
    "            \n",
    "            # 이후 \"bidirectional_dynamic_rnn\"기능을 통해 양방향 lstm 구현\n",
    "            (fw_outputs, bw_outputs), _ = tf.nn.bidirectional_dynamic_rnn(cell_fw = multi_lstm_fw,\n",
    "                                                       cell_bw = multi_lstm_bw,\n",
    "                                                       inputs = inputs,\n",
    "                                                       dtype = tf.float32)\n",
    "            outputs = tf.concat([fw_outputs, bw_outputs], 2)\n",
    "            \n",
    "            return outputs[:,-1,:]\n",
    "    embedding = tf.keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "    \n",
    "    base_embedded_matrix = embedding(features['base'])\n",
    "    hypothesis_embedded_matrix = embedding(features['hypothesis'])\n",
    "    \n",
    "    base_sementic_matrix = basic_bilstm_network(base_embedded_matrix, 'base')\n",
    "    hypothesis_sementic_matrix = basic_bilstm_network(hypothesis_embedded_matrix, 'hypothesis')\n",
    "    \n",
    "    base_sementic_matrix = tf.keras.layers.Dropout(DROPOUT_RATIO)(base_sementic_matrix)\n",
    "    hypothesis_sementic_matrix = tf.keras.layers.Dropout(DROPOUT_RATIO)(hypothesis_sementic_matrix)\n",
    "    \n",
    "    logit_layer = tf.exp(-tf.reduce_sum(tf.abs(base_sementic_matrix - hypothesis_sementic_matrix), axis = 1, keepdims = True))\n",
    "    logit_layer = tf.squeeze(logit_layer, axis = -1)\n",
    "    \n",
    "    if PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "                  mode=mode,\n",
    "                  predictions={\n",
    "                      'is_duplicate':logit_layer\n",
    "                  })\n",
    "        #prediction 진행 시, None\n",
    "    if labels is not None:\n",
    "        labels = tf.to_float(labels)\n",
    "        \n",
    "    loss = tf.losses.mean_squared_error(labels=labels, predictions=logit_layer)\n",
    "    \n",
    "    if EVAL:\n",
    "        accuracy = tf.metrics.accuracy(labels, tf.round(logit_layer))\n",
    "        eval_metric_ops = {'acc': accuracy}\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "                  mode=mode,\n",
    "                  eval_metric_ops= eval_metric_ops,\n",
    "                  loss=loss)\n",
    "    elif TRAIN:\n",
    "\n",
    "        global_step = tf.train.get_global_step()\n",
    "        train_op = tf.train.AdamOptimizer(1e-3).minimize(loss, global_step)\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "                  mode=mode,\n",
    "                  train_op=train_op,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/Users/weehyerin/tensorflow-ml-nlp/5.TEXT_SIM/./data_out//checkpoint/rnn2/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x134243908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model_dir = os.path.join(os.getcwd(), DATA_OUT_PATH + \"/checkpoint/rnn2/\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "config_tf = tf.estimator.RunConfig()\n",
    "\n",
    "lstm_est = tf.estimator.Estimator(Malstm, model_dir=model_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-8-2968e2d3efc6>:12: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-8-2968e2d3efc6>:19: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-8-2968e2d3efc6>:26: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-8-2968e2d3efc6>:52: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /Users/weehyerin/tensorflow-ml-nlp/5.TEXT_SIM/./data_out//checkpoint/rnn2/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.23771498, step = 1\n",
      "INFO:tensorflow:global_step/sec: 3.71112\n",
      "INFO:tensorflow:loss = 0.22100651, step = 101 (26.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27169\n",
      "INFO:tensorflow:loss = 0.25732785, step = 201 (23.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.03218\n",
      "INFO:tensorflow:loss = 0.16112627, step = 301 (24.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33188\n",
      "INFO:tensorflow:loss = 0.28588435, step = 401 (23.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.40273\n",
      "INFO:tensorflow:loss = 0.14475511, step = 501 (22.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46739\n",
      "INFO:tensorflow:loss = 0.27575788, step = 601 (22.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.56737\n",
      "INFO:tensorflow:loss = 0.25827283, step = 701 (21.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28889\n",
      "INFO:tensorflow:loss = 0.28879893, step = 801 (23.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.26545\n",
      "INFO:tensorflow:loss = 0.30915266, step = 901 (23.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.37952\n",
      "INFO:tensorflow:loss = 0.24241316, step = 1001 (22.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.64101\n",
      "INFO:tensorflow:loss = 0.25150996, step = 1101 (21.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.17916\n",
      "INFO:tensorflow:loss = 0.23765123, step = 1201 (23.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.63464\n",
      "INFO:tensorflow:loss = 0.23072898, step = 1301 (21.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48809\n",
      "INFO:tensorflow:loss = 0.120269835, step = 1401 (22.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.64131\n",
      "INFO:tensorflow:loss = 0.24477468, step = 1501 (21.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.6439\n",
      "INFO:tensorflow:loss = 0.25655353, step = 1601 (21.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.66321\n",
      "INFO:tensorflow:loss = 0.13986659, step = 1701 (21.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.65263\n",
      "INFO:tensorflow:loss = 0.09186769, step = 1801 (21.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.5867\n",
      "INFO:tensorflow:loss = 0.21279185, step = 1901 (21.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.14118\n",
      "INFO:tensorflow:loss = 0.19008818, step = 2001 (24.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.56358\n",
      "INFO:tensorflow:loss = 0.061324842, step = 2101 (21.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.01716\n",
      "INFO:tensorflow:loss = 0.21329749, step = 2201 (24.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.09452\n",
      "INFO:tensorflow:loss = 0.17910136, step = 2301 (24.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.26071\n",
      "INFO:tensorflow:loss = 0.17207691, step = 2401 (23.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.05579\n",
      "INFO:tensorflow:loss = 0.057882115, step = 2501 (24.656 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2580 into /Users/weehyerin/tensorflow-ml-nlp/5.TEXT_SIM/./data_out//checkpoint/rnn2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.9049\n",
      "INFO:tensorflow:loss = 0.17923108, step = 2601 (25.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52562\n",
      "INFO:tensorflow:loss = 0.16136806, step = 2701 (22.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.73181\n",
      "INFO:tensorflow:loss = 0.2698242, step = 2801 (21.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.3408\n",
      "INFO:tensorflow:loss = 0.18258803, step = 2901 (23.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.35986\n",
      "INFO:tensorflow:loss = 0.106815994, step = 3001 (22.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27605\n",
      "INFO:tensorflow:loss = 0.19690105, step = 3101 (23.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.22955\n",
      "INFO:tensorflow:loss = 0.18241715, step = 3201 (23.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.24872\n",
      "INFO:tensorflow:loss = 0.09627564, step = 3301 (23.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27487\n",
      "INFO:tensorflow:loss = 0.28372803, step = 3401 (23.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.74699\n",
      "INFO:tensorflow:loss = 0.12262817, step = 3501 (26.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.77882\n",
      "INFO:tensorflow:loss = 0.27795753, step = 3601 (26.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.13345\n",
      "INFO:tensorflow:loss = 0.23374136, step = 3701 (24.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.7349\n",
      "INFO:tensorflow:loss = 0.23786941, step = 3801 (26.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33772\n",
      "INFO:tensorflow:loss = 0.11255267, step = 3901 (23.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.09247\n",
      "INFO:tensorflow:loss = 0.13023838, step = 4001 (24.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.31024\n",
      "INFO:tensorflow:loss = 0.11742444, step = 4101 (23.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.10968\n",
      "INFO:tensorflow:loss = 0.22423834, step = 4201 (24.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.19884\n",
      "INFO:tensorflow:loss = 0.19417901, step = 4301 (23.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.24209\n",
      "INFO:tensorflow:loss = 0.26904726, step = 4401 (23.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.85879\n",
      "INFO:tensorflow:loss = 0.16591522, step = 4501 (25.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.5118\n",
      "INFO:tensorflow:loss = 0.18228991, step = 4601 (22.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.66567\n",
      "INFO:tensorflow:loss = 0.18152541, step = 4701 (21.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.39309\n",
      "INFO:tensorflow:loss = 0.22162828, step = 4801 (22.764 sec)\n"
     ]
    }
   ],
   "source": [
    "lstm_est.train(train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_est.evaluate(eval_input_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
